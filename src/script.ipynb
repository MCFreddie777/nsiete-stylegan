{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591946aa",
   "metadata": {},
   "source": [
    "# StyleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76504b",
   "metadata": {},
   "source": [
    "Dataset: [https://ai.stanford.edu/~jkrause/cars/car_dataset.html](https://ai.stanford.edu/~jkrause/cars/car_dataset.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4507a56b",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78288e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/docs &> /dev/null\n",
    "!pip install imageio wandb &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import datetime\n",
    "\n",
    "from IPython import display\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import backend\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202123c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422efafb",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'IMAGE_HEIGHT': 128,\n",
    "    'IMAGE_WIDTH': 128,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "data_compressed_filename_train = 'cars_train.tgz'\n",
    "data_extracted_foldername = 'cars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1129c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(tar_url, dir):\n",
    "    if not (os.path.exists(f\"{data_path}/{data_extracted_foldername}/{dir}\")):\n",
    "        tar = tarfile.open(f\"{data_path}/{tar_url}\", 'r')\n",
    "        for item in tar:\n",
    "            tar.extract(item, f\"{data_path}/{data_extracted_foldername}/{dir}\")\n",
    "            if item.name.find(\".tgz\") != -1 or item.name.find(\".tar\") != -1:\n",
    "                extract(item.name, \"./\" + item.name[:item.name.rfind('/')])\n",
    "\n",
    "extract(data_compressed_filename_train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1338f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    image_list = []\n",
    "    \n",
    "    for filename in glob.glob(f'{data_path}/{data_extracted_foldername}/train/cars_train/*.jpg'): \n",
    "        image = Image.open(filename).resize((config['IMAGE_HEIGHT'], config['IMAGE_WIDTH']))\n",
    "        image = np.asarray(image)\n",
    "\n",
    "        if len(image.shape) == 3: # take only rgb images\n",
    "            image_list.append(image)\n",
    "    \n",
    "    return np.asarray(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3, 3, 1 + i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(train_images[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5f653",
   "metadata": {},
   "source": [
    "Optimize by converting from unsigned ints to floats and scale from [0,255] to [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebe808",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c187d8b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5aee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)\n",
    "\n",
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(keras.constraints.Constraint):\n",
    "\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    **config,\n",
    "    \"EPOCHS\": 200,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"LEARNING_RATE\": 0.00005, # wgan\n",
    "    # \"LEARNING_RATE\": 0.0002,\n",
    "    \"BETA\": 0.5,\n",
    "    \"LOSS\": wasserstein_loss,\n",
    "    # \"LOSS\": 'binary_crossentropy',\n",
    "    \"LATENT_DIM\":100,\n",
    "    'D_DROPOUT': 0.4,\n",
    "    'D_OUTPUT_ACTIVATION': 'linear', # wgan\n",
    "    # 'D_OUTPUT_ACTIVATION': 'sigmoid', # wgan\n",
    "    'N_CRITIC': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa560e83",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def define_discriminator(in_shape=(config['IMAGE_HEIGHT'],config['IMAGE_WIDTH'],3)):\n",
    "#     # weight initialization\n",
    "#     init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "#     # define model\n",
    "#     model = tf.keras.Sequential()\n",
    "\n",
    "#     # normal\n",
    "#     model.add(layers.Conv2D(64, (3,3), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "#     # downsample to 64x64\n",
    "#     model.add(layers.Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "#     # downsample to 32x32\n",
    "#     model.add(layers.Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "#     # downsample to 16x16\n",
    "#     model.add(layers.Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "#     model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "#     # classifier\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dropout(config[\"D_DROPOUT\"]))\n",
    "#     model.add(layers.Dense(1, activation=config['D_OUTPUT_ACTIVATION']))\n",
    "\n",
    "#     # compile model\n",
    "#     opt = keras.optimizers.Adam(lr=config['LEARNING_RATE'], beta_1=config['BETA'])\n",
    "#     model.compile(loss=config['LOSS'], optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# discriminator = define_discriminator()\n",
    "# plot_model(discriminator, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4dc73",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_critic(in_shape=(config['IMAGE_HEIGHT'], config['IMAGE_WIDTH'], 3)):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    # weight constraint\n",
    "    const = ClipConstraint(0.01)\n",
    "\n",
    "    # define model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # downsample to 64x64\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # downsample to 32x32\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # downsample to 16x16\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # downsample to 8x8\n",
    "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # scoring, linear activation\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=config['D_OUTPUT_ACTIVATION']))\n",
    "\n",
    "    # optimizer\n",
    "    opt = keras.optimizers.RMSprop(lr=config['LEARNING_RATE'])  # wgan\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss=config['LOSS'], optimizer=opt)\n",
    "\n",
    "    return model\n",
    "\n",
    "critic = define_critic()\n",
    "plot_model(critic, to_file='critic_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf58894",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f59496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(input_dim=config['LATENT_DIM']):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    # define model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # foundation for 4x4 image\n",
    "    n_nodes = 256 * 4 * 4\n",
    "\n",
    "    model.add(layers.Dense(n_nodes, kernel_initializer=init, input_dim=input_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Reshape((4, 4, 256)))\n",
    "\n",
    "    # upsample to 8x8\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # upsample to 16x16\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # upsample to 32x32\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # upsample to 64x64\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # upsample to 128x128\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # output 128x128x3\n",
    "    model.add(layers.Conv2D(3, (4, 4), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = define_generator()\n",
    "plot_model(generator, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcecb4e",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, critic):\n",
    "\n",
    "    # make weights in the critic not trainable\n",
    "    for layer in critic.layers:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            critic.trainable = False\n",
    "    \n",
    "    # define model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "\n",
    "    # add the criticz\n",
    "    model.add(critic)\n",
    "\n",
    "    # optimizer\n",
    "    opt = keras.optimizers.RMSprop(lr=config['LEARNING_RATE']) #wgab\n",
    "    # opt = keras.optimizers.Adam(lr=config['LEARNING_RATE'], beta_1=config['BETA'])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss=config['LOSS'], optimizer=opt)\n",
    "\n",
    "    return model\n",
    "\n",
    "gan = define_gan(generator,critic)\n",
    "plot_model(gan, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47471d4",
   "metadata": {},
   "source": [
    "## Traing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_dir_exists(filepath):\n",
    "    directory = os.path.dirname(filepath)\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    return filepath\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    \"\"\"\n",
    "    select real samples\n",
    "    \"\"\"\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "\n",
    "    # wgan\n",
    "    y = -np.ones((n_samples, 1))\n",
    "    # y = np.ones((n_samples, 1))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    \"\"\"\n",
    "    generate points in latent space as input for the generator\n",
    "    \"\"\"\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "\n",
    "    return x_input\n",
    "\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    \"\"\"\n",
    "    use the generator to generate n fake examples, with class labels\n",
    "    \"\"\"\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input)\n",
    "\n",
    "    y = np.ones((n_samples, 1))  # wgan\n",
    "    # y = np.zeros((n_samples, 1))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def save_model(epoch, g_model, model_path):\n",
    "    # save locally\n",
    "    filename = check_if_dir_exists(f'{model_path}/generator_model_{(epoch + 1):04d}.h5')\n",
    "    g_model.save(filename)\n",
    "\n",
    "    # save to wandb\n",
    "    wandb_run.save(filename)\n",
    "\n",
    "\n",
    "def save_plot(epoch, images_path, g_model, latent_dim, n_samples=150, n=7):\n",
    "    \"\"\"\n",
    "    create and save a plot of generated images\n",
    "    \"\"\"\n",
    "\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X + 1) / 2.0\n",
    "\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X[i])\n",
    "\n",
    "    # save plot to file\n",
    "    image_name = f\"generated_plot_e{(epoch + 1):04d}.png\"\n",
    "    filename = check_if_dir_exists(f'{images_path}/{image_name}')\n",
    "    plt.savefig(filename)\n",
    "\n",
    "    # save to wandb\n",
    "    wandb_run.log({\"images\": wandb.Image(plt, caption=image_name)})\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128, run=0, n_critic=5):\n",
    "    \"\"\"\n",
    "    train the generator and critic\n",
    "    \"\"\"\n",
    "    \n",
    "    model_path = f'runs/{run}/models'\n",
    "    images_path = f'runs/{run}/images'\n",
    "\n",
    "    time_train_start = time.time()\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        time_epoch_start = time.time()\n",
    "\n",
    "        c1_epoch, c2_epoch, gan_epoch = list(), list(), list()\n",
    "        for j in range(bat_per_epo):\n",
    "\n",
    "            # update the critic more than the generator\n",
    "            # c1_batch, c2_batch = list(), list()\n",
    "            # for _ in range(n_critic):\n",
    " \n",
    "            # real\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "            c1_batch.append(c_loss1)\n",
    "\n",
    "            # fake\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "            c2_batch.append(c_loss2)\n",
    "\n",
    "            # store critic loss\n",
    "            c1_epoch.append(c_loss1)\n",
    "            c2_epoch.append(c_loss2)\n",
    "\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = -np.ones((n_batch, 1))  # wgan\n",
    "            # y_gan = np.ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            gan_epoch.append(g_loss)\n",
    "\n",
    "        c1_loss = np.mean(c1_epoch)\n",
    "        c2_loss = np.mean(c2_epoch)\n",
    "        g_loss = np.mean(gan_epoch)\n",
    "\n",
    "        time_since_start = str(datetime.timedelta(seconds=(time.time() - time_train_start)))\n",
    "        print(f'({time_since_start}) [{i + 1}/{config[\"EPOCHS\"]}]: c1={c1_loss:.3f}, c2={c2_loss:.3f}, g={g_loss:.3f}, took {time.time() - time_epoch_start} seconds')\n",
    "        \n",
    "        wandb_run.log({\n",
    "            'c_real_loss': c1_loss,\n",
    "            'c_fake_loss': c2_loss,\n",
    "            'gan_loss': g_loss,\n",
    "            'epoch_time': time.time() - time_epoch_start\n",
    "        }, step=i + 1)\n",
    "\n",
    "        # save image\n",
    "        save_plot(i, images_path, g_model, latent_dim)\n",
    "\n",
    "        # save model every sometimes\n",
    "        if (i + 1) % 10 == 0:\n",
    "            save_model(i, g_model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 9\n",
    "notes ='WGAN training 2'\n",
    "\n",
    "wandb_run = wandb.init(project=\"styleGAN\", entity=\"nn2021\",name=f'gcp_run_{run}', notes=notes)\n",
    "wandb_run.config.update(config)\n",
    "\n",
    "for image in ['generator_plot.png', 'critic_plot.png', 'gan_plot.png']:\n",
    "    wandb_run.save(image)\n",
    "\n",
    "train(\n",
    "    g_model=generator,\n",
    "    c_model=critic,\n",
    "    gan_model=gan, \n",
    "    dataset=train_images, \n",
    "    latent_dim=config['LATENT_DIM'],\n",
    "    n_epochs=config['EPOCHS'],\n",
    "    n_batch=config['BATCH_SIZE'],\n",
    "    run=run,\n",
    "    n_critic=config['N_CRITIC']\n",
    ")\n",
    "\n",
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32072ca",
   "metadata": {},
   "source": [
    "###### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a652d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_for_epoch(epoch_no, run):\n",
    "    return Image.open(f'runs/{run}/images/generated_plot_e{epoch_no:04d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_for_epoch(1, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a96592",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_for_epoch(100,run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c94b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_for_epoch(200,run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3b6ce",
   "metadata": {},
   "source": [
    "Display images after epochs in gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf65533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gif(run):\n",
    "    anim_file = f'runs/{run}/dcgan.gif'\n",
    "\n",
    "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "        filenames = glob.glob(f'runs/{run}/images/generated_plot_e*.png')\n",
    "        filenames = sorted(filenames)\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            \n",
    "    return anim_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(generate_gif(run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b8cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "last_run = api.run(f\"{wandb_run.entity}/{wandb_run.project}/{wandb_run.id}\")\n",
    "last_run.upload_file(f'runs/{run}/dcgan.gif')\n",
    "last_run.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a268841",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdefe4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(examples, n):\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(examples[i, :, :])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate(model,latent_points,amount=4):\n",
    "    X = model.predict(latent_points)\n",
    "    X = (X + 1) / 2.0\n",
    "    create_plot(X, amount)\n",
    "    \n",
    "def load_model(run, epoch):\n",
    "    return keras.models.load_model(f'runs/{run}/models/generator_model_{epoch:04d}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(run,200)\n",
    "latent_points = generate_latent_points(100,100)\n",
    "generate(model,latent_points,amount=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.asarray([[0.75 for _ in range(100)]])\n",
    "X = model.predict(vector)\n",
    "X = (X + 1) / 2.0\n",
    "plt.imshow(X[0, :, :])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}